RAPPORT DE PROJET : Système de Correction Orthographique Automatique (TALN)

Auteur : Manohisitraka

Niveau : Master 2

Matière : Traitement Automatique du Langage Naturel (TALN)

Année : 2026
1. Introduction

Le Traitement Automatique du Langage Naturel (TALN) est un domaine à la croisée de l'informatique et de la linguistique qui vise à permettre aux machines de comprendre et de manipuler le langage humain.

Ce projet, baptisé CorTexte, porte sur la correction orthographique et grammaticale automatique. L'objectif est de proposer une solution capable de détecter non seulement les fautes de frappe (niveaux lexical), mais aussi les erreurs de syntaxe, de conjugaison et d'accord (niveau grammatical). Pour ce faire, nous avons développé une architecture logicielle moderne séparant le moteur d'analyse linguistique (Backend) de l'interface utilisateur (Frontend).
2. Architecture du Projet

Le projet repose sur une architecture Client-Serveur robuste :

    Le Serveur (Moteur de correction) : Une instance locale de LanguageTool gérant les règles linguistiques complexes.

    L'Interface (Application Web) : Une application moderne développée en React JS permettant une interaction fluide.

    La Communication : Utilisation du protocole HTTP (API REST) pour l'échange de données entre le client et le serveur.

3. Technologies et Outils Utilisés
A. Technologies Backend & Linguistiques

    LanguageTool (v6.6) : C'est le cœur du projet. Il s'agit d'un correcteur open-source écrit en Java. Nous l'utilisons en mode serveur (HTTPServer) pour traiter les requêtes en temps réel.

    Java 17 (JDK) : Utilisé pour faire fonctionner le moteur LanguageTool avec une gestion optimisée de la mémoire vive (-Xmx1024m) pour garantir la rapidité de l'analyse sur Fedora.

    Python (Phase de prototypage) : Initialement utilisé pour tester les appels API via la bibliothèque requests avant de passer au développement web.

B. Technologies Frontend (Interface Utilisateur)

    React JS (Vite) : Framework choisi pour sa rapidité et sa gestion des composants. Il permet une interface réactive où les corrections s'affichent sans recharger la page.

    Tailwind CSS (v3) : Framework CSS utilisé pour le design. Il a permis de réaliser une interface "Dark Mode" et "Light Mode" élégante avec des composants modernes (cartes de suggestions, arrondis rounded-3xl).

    Axios : Bibliothèque JavaScript utilisée pour envoyer le texte au serveur Java et récupérer les suggestions de remplacement.

    ESLint : Utilisé pour garantir la qualité du code et le respect des normes de programmation modernes.

4. Fonctionnement Technique (Algorithmique)

L'un des défis majeurs de ce projet a été la reconstruction du texte corrigé. Lorsqu'une erreur est détectée, le serveur renvoie un offset (position) et une length (longueur).

Logique de correction implémentée : Pour éviter de décaler les positions des erreurs suivantes lors du remplacement d'un mot par un autre de longueur différente, nous avons implémenté un algorithme de tri inverse :

    Récupération de la liste des erreurs (matches).

    Tri des erreurs par position décroissante (de la fin vers le début du texte).

    Remplacement successif des segments de texte. Cette méthode garantit que la modification d'un mot au début du texte n'impacte pas l'index des mots restants à traiter.

Ajout au Rapport : Communication et Bibliothèques Python
1. L'utilisation d'une API REST

Le projet repose sur une architecture API REST (Representational State Transfer).

    Le Serveur (Java/LanguageTool) expose des "points de terminaison" (endpoints), notamment http://localhost:8081/v2/check.

    Le Client (React ou Python) envoie des requêtes HTTP POST. Le corps de la requête contient le texte brut, et le serveur répond avec un objet JSON structuré contenant les erreurs et les suggestions.

    Cette approche permet de découpler totalement l'interface du moteur : on peut changer l'apparence sans jamais toucher au code de correction.

2. Rôle de Requests (Python)

Lors de la phase de conception et de prototypage, nous avons utilisé la bibliothèque requests en Python.

    Utilité : Elle nous a permis de tester la connectivité avec le serveur API REST de manière simple et rapide.

    Fonctionnement : Grâce à requests.post(), nous avons pu simuler l'envoi de texte et analyser la structure des données JSON renvoyées par le serveur avant de coder l'interface finale en React.

3. Rôle de Pyspellchecker

Pour enrichir la phase de recherche et comprendre les mécanismes de correction purement lexicale, nous avons exploré pyspellchecker.

    Analyse Lexicale : Contrairement à LanguageTool qui analyse la grammaire, pyspellchecker se base sur la distance de Levenshtein pour trouver des mots proches dans un dictionnaire.

    Apport au projet : Cette étape a permis de comparer les approches basées sur des dictionnaires statiques (Python) par rapport aux approches basées sur des règles linguistiques complexes (Java/LanguageTool), justifiant ainsi le choix final de LanguageTool pour une correction de niveau Master 2.

4. Fonctionnement de l'Algorithme et Logique de Traitement

Le cœur du projet repose sur le passage d'une correction statique à une correction contextuelle.
A. Étude comparative : Lexique vs Grammaire

Au début du projet, nous avons exploré la bibliothèque pyspellchecker. Son algorithme repose sur la distance de Levenshtein, qui calcule le nombre minimal de modifications (insertions, suppressions, substitutions) pour transformer un mot erroné en un mot correct du dictionnaire.

    Limitation : Cette approche corrige "manger" en "mangé", mais elle est incapable de savoir laquelle des deux formes est correcte selon le sujet de la phrase.

B. L'approche par API REST et Analyse de Règles

Pour pallier cette limite, nous avons implémenté l'algorithme via l'API REST de LanguageTool. Contrairement à pyspellchecker, cet algorithme n'analyse pas les mots isolés, mais des chaînes de jetons (tokens).

    Requête (Request) : Le frontend envoie le texte brut via une méthode POST à l'URL du serveur.

    Analyse : Le serveur applique des milliers de règles de désambiguïsation (ex: "est" verbe vs "est" point cardinal).

    Réponse (Response) : Le serveur renvoie un objet JSON contenant les matches. Chaque match définit précisément l'erreur par son offset (index de départ) et sa length (longueur).

C. L'Algorithme de Reconstruction (Tri Inverse)

Le défi technique majeur réside dans la modification de la chaîne de caractères originale. Si l'on remplace un mot de 4 lettres par un mot de 7 lettres au début du texte, tous les index (offset) des erreurs suivantes deviennent faux.

Pour résoudre ce problème, nous avons conçu l'algorithme suivant :

    Récupération de l'ensemble des erreurs détectées.

    Tri (Sorting) de la liste des erreurs par ordre décroissant de leur offset.

        Logique : En commençant par la fin du texte, les modifications de longueur n'impactent que la partie que nous avons déjà traitée ou qui ne contient plus d'erreurs. Les index des erreurs situées au début restent donc valides.

    Splicing : Utilisation de la méthode splice (ou manipulation de listes en Python) pour injecter la suggestion à l'emplacement exact.

5. Conclusion

Le projet CorTexte démontre l'efficacité de combiner des outils linguistiques éprouvés (Java/LanguageTool) avec des technologies web modernes (React/Tailwind). Le système est capable de traiter des textes longs avec une faible latence tout en offrant une expérience utilisateur intuitive et professionnelle.
Annexe : Commandes de lancement

    Lancement Serveur : java -Xmx1024m -cp languagetool-server.jar org.languagetool.server.HTTPServer --port 8081 --allow-origin

    Lancement Interface : npm run dev

Souhaites-tu que j'ajoute une section sur les "Perspectives d'amélioration" (comme l'ajout d'une IA de type LLM ou la gestion de fichiers PDF) pour enrichir encore plus ton rapport ?
